{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework (10 points)\n",
    "\n",
    "In this homework we train Sound Event Detection model.\n",
    "\n",
    "Dataset: https://disk.yandex.ru/d/NRpDIp4jg2ODqg\n",
    "\n",
    "Hint to download from yadisk. To get real download link for wget or curl you need:\n",
    "- Open developer console and go to the network tab\n",
    "- Press download button\n",
    "- find \"download-url\" on the network tab and copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download dataset\n",
    "!wget -O data.tar.gz \"https://downloader.disk.yandex.ru/disk/4c5d0c8924b383512ea1af6e7ebe0835dfaf863ca5e1920d7d78076ffedf38f4/65baef2b/gtj3WQiuHGabqHv6W0pVHNHKJOSrL1Ndqw5DdKyJakWvM0_u-aVydaSJ9SFBTCXqkDf5pEJT-jL3E5RuN55B9A%3D%3D?uid=0&filename=sound_event_detection.tar.gz&disposition=attachment&hash=cFvndBq/xOwr18kbjbvCR1M9L3Wj1pzfVE929UmDTjP2u%2BA0B6mbXpTOy5mLcun8q/J6bpmRyOJonT3VoXnDag%3D%3D&limit=0&content_type=application%2Fx-gzip&owner_uid=163052607&fsize=10308787085&hid=51bb9b7fb344746dbead9fd66c87e539&media_type=compressed&tknv=v2\"\n",
    "!tar -xvf data.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tqdm.notebook as tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as torch_data\n",
    "import torchaudio\n",
    "\n",
    "# realization of Dataset for given data\n",
    "import dataset\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cpu' # also you can use \"cuda\" for gpu and \"mps\" for apple silicon\n",
    "DATADIR = 'data'\n",
    "LOADER_WORKERS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FBANK 80 by default, but you can choose something else\n",
    "transform = torchaudio.transforms.MelSpectrogram(n_mels=80)\n",
    "trainset = dataset.Dataset('train', 'data', transform)\n",
    "testset = dataset.Dataset('eval', 'data', transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval part (1 point)\n",
    "\n",
    "Write balanced accuracy:\n",
    "$$BAcc = \\frac{1}{classes}\\sum_{c = 1}^{classes} \\frac{\\sum_i^n I(y_i = p_i = c)}{\\sum_i^n I(y_i = c)}$$\n",
    "\n",
    "Where:\n",
    "- $y_i$ -- target class for $i$ element\n",
    "- $p_i$ -- predicted class for $i$ element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of pairs (target_class, predicted_class)\n",
    "def balanced_accuracy(items: list[tuple[int, int]]) -> float:\n",
    "    <YOUR CODE IS HERE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.isclose(balanced_accuracy([(0, 0), (0, 0), (1, 1)]), 1.0)\n",
    "assert np.isclose(balanced_accuracy([(0, 1), (1, 0)]), 0.0)\n",
    "assert np.isclose(balanced_accuracy([(0, 0), (0, 0), (1, 0)]), 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train part (9 points)\n",
    "\n",
    "Train some model with test accuracy > 0.5\n",
    "\n",
    "You can train any model you want. The only limitation is that it must be trained from scratch on the data provided in the task. For example you can choose model from:\n",
    "- DNN\n",
    "- CNN 1d\n",
    "- CNN 2d\n",
    "- Transformer\n",
    "- RNN\n",
    "- mixes of given models\n",
    "\n",
    "Hints:\n",
    "- No need to train large models for this task. 10 million parameters is more than you need.\n",
    "- Watch to overfitting, try to add Augmentation, Dropout, BatchNorm, L1/L2-Regulatization or something else.\n",
    "- Use poolings or strides to reduce time-dimenstion. It is better to reduce the dimension gradually rather than at the end.\n",
    "- Try different features (mel-spec, log-mel-spec, mfcc)\n",
    "\n",
    "P.S. Points can be deducted for unclear training charts\n",
    "\n",
    "PP.S. A partial score will be awarded for a test accuracy < 0.5\n",
    "\n",
    "PPP.S. Add log to Melspectrogram in torchaudio.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stage(\n",
    "    model: nn.Module,\n",
    "    data: dataset.Dataset,\n",
    "    loss_fun: nn.Module,\n",
    "    opt: optim.Optimizer,\n",
    "    batch_size: int = 256,\n",
    "    train: bool = True\n",
    "):\n",
    "    loader = torch_data.DataLoader(\n",
    "        data,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=LOADER_WORKERS,\n",
    "        collate_fn=dataset.collate_fn\n",
    "    )\n",
    "    if train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    loss_sum, batches = 0.0, 0\n",
    "    pred_pairs = []\n",
    "    for X, Y in tqdm.tqdm(loader):\n",
    "        pred = model.forward(X.to(DEVICE))\n",
    "        loss = loss_fun(pred, Y.to(DEVICE))\n",
    "        if train:\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        loss_sum += loss.item()\n",
    "        batches += 1\n",
    "        with torch.no_grad():\n",
    "            pred_pairs.extend(zip(\n",
    "                Y.data.numpy().reshape(-1),\n",
    "                torch.argmax(pred, dim=1).cpu().data.numpy().reshape(-1)\n",
    "            ))\n",
    "    return loss_sum / batches, balanced_accuracy(pred_pairs)\n",
    "\n",
    "\n",
    "def train(\n",
    "    model: nn.Module,\n",
    "    opt,\n",
    "    batch_size: int = 256,\n",
    "    epochs: int = 10,\n",
    "):\n",
    "    train_losses, test_losses, train_accs, test_accs = [], [], [], []\n",
    "    for epoch in range(epochs):\n",
    "        train_loss, train_acc = stage(model, trainset, opt, batch_size=batch_size)\n",
    "        test_loss, test_acc = stage(model, testset, opt, batch_size=batch_size, train=False)\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        test_losses.append(test_loss)\n",
    "        test_accs.append(test_acc)\n",
    "        clear_output()\n",
    "        fig, axis = plt.subplots(1, 2, figsize=(15, 7))\n",
    "        axis[0].plot(np.arange(1, epoch + 2), train_losses, label='train')\n",
    "        axis[0].plot(np.arange(1, epoch + 2), test_losses, label='test')\n",
    "        axis[1].plot(np.arange(1, epoch + 2), train_accs, label='train')\n",
    "        axis[1].plot(np.arange(1, epoch + 2), test_accs, label='test')\n",
    "        axis[0].set(xlabel='epoch', ylabel='CE Loss')\n",
    "        axis[1].set(xlabel='epoch', ylabel='Accuracy')\n",
    "        fig.legend()\n",
    "        plt.show()\n",
    "        print(f'Epoch {epoch + 1}.')\n",
    "        print(f'Train loss {train_loss}. Train accuracy {train_acc}.')\n",
    "        print(f'Eval loss {train_loss}. Eval accuracy {train_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    <YOUR CODE IS HERE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "opt = optim.Adam(model.parameters())\n",
    "train(model, opt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
